---
title: Quickstart
description: "Get Kernle running in 5 minutes"
---

## Installation

<Tabs>
  <Tab title="pip">
    ```bash
    pip install kernle
    ```
  </Tab>
  <Tab title="uv">
    ```bash
    uv pip install kernle
    ```
  </Tab>
  <Tab title="pipx">
    ```bash
    pipx install kernle
    ```
  </Tab>
</Tabs>

## Initialize

```bash
# Initialize with your stack ID
kernle -s your-stack-name init

# Or let it auto-detect your environment
kernle init
```

This creates `~/.kernle/` with your local database.

## Basic Usage

### Capture Memories

```bash
# Quick capture (zero friction)
kernle -s mystack raw "Just learned about memory consolidation"

# Structured note
kernle -s mystack note "Memory consolidation happens during reflection" \
  --type insight

# Full episode
kernle -s mystack episode "Debugging the sync bug" \
  "Found the race condition in the queue handler" \
  --lesson "Always check for concurrent access"
```

### Search and Retrieve

```bash
# Semantic search
kernle -s mystack search "sync issues"

# Load working memory for a session
kernle -s mystack load

# Check memory health
kernle -s mystack anxiety
```

### Save State

```bash
# Save a checkpoint before ending session
kernle -s mystack checkpoint save "end of work session"

# Restore later
kernle -s mystack checkpoint load
```

## Python API

<Tabs>
  <Tab title="Library Usage">
    ```python
    from kernle.entity import Entity
    from kernle.stack import SQLiteStack
    from kernle.models.anthropic import AnthropicModel

    # Create the core
    entity = Entity()

    # Bind a model
    entity.set_model(AnthropicModel())

    # Attach a memory stack
    stack = SQLiteStack(db_path="~/.kernle/stacks/mystack/memory.db")
    entity.attach_stack(stack, alias="mystack", set_active=True)

    # Write memories (with full provenance)
    entity.episode(
        "Optimized the sync pipeline",
        "Reduced latency from 300ms to 100ms",
        lessons=["Batching network calls is worth the complexity"],
    )

    entity.belief(
        "Batch processing outperforms sequential I/O",
        confidence=0.85,
    )

    # Search
    results = entity.search("performance optimization")
    for r in results:
        print(f"{r.memory_type}: {r.content[:80]}")

    # Load working memory
    context = entity.load(token_budget=8000)
    ```
  </Tab>
  <Tab title="With Plugins">
    ```python
    from kernle.entity import Entity
    from kernle.stack import SQLiteStack

    entity = Entity()
    stack = SQLiteStack(db_path="memory.db")
    entity.attach_stack(stack)

    # Discover installed plugins
    available = entity.discover_plugins()
    for p in available:
        print(f"Found: {p.name} v{p.version}")

    # Load a plugin (e.g., chainbased for commerce)
    from chainbased import ChainbasedPlugin
    entity.load_plugin(ChainbasedPlugin())

    # The plugin writes memories through PluginContext
    # with automatic source attribution

    # Unload when done -- only memories remain
    entity.unload_plugin("chainbased")
    ```
  </Tab>
</Tabs>

## MCP Integration

Add Kernle to Claude Desktop:

```json
// ~/Library/Application Support/Claude/claude_desktop_config.json
{
  "mcpServers": {
    "kernle": {
      "command": "kernle",
      "args": ["mcp", "--stack", "claude"]
    }
  }
}
```

Restart Claude Desktop. You'll have access to memory tools like `memory_load`, `memory_search`, `memory_checkpoint_save`, etc.

## Cloud Sync (Optional)

```bash
# Register for cloud sync
kernle -s mystack auth register

# Check sync status
kernle -s mystack sync status

# Push local changes
kernle -s mystack sync push

# Pull from cloud
kernle -s mystack sync pull
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Memory Model" icon="brain" href="/concepts/memory-model">
    Understand the memory layers
  </Card>
  <Card title="CLI Reference" icon="terminal" href="/cli/overview">
    Full command documentation
  </Card>
</CardGroup>
