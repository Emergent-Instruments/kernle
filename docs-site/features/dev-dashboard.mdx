---
title: "Dev Dashboard"
description: "Local web dashboard for visually inspecting memory stacks"
---

The dev dashboard is a self-contained tool for visually inspecting kernle memory stacks. It serves an interactive dark-themed web UI on localhost, giving you a complete view of raw entries, promoted memories, provenance chains, anxiety scores, processing status, and audit trails.

## Quick Start

```bash
python dev/dashboard.py --stack my-agent
# Opens http://localhost:8420
```

The dashboard opens in your browser automatically. No additional dependencies are required beyond kernle itself — the dashboard uses only Python standard library (`http.server`, `json`).

## Options

| Flag | Default | Description |
|------|---------|-------------|
| `--stack, -s` | (required) | Stack ID to inspect |
| `--port, -p` | 8420 | Port to serve on |
| `--no-open` | off | Don't auto-open browser |
| `--verbose, -v` | off | Verbose server logging |

## Dashboard Tabs

### Overview

Stats cards showing counts for each memory type (raw entries, episodes, beliefs, values, goals, notes, relationships, drives, suggestions). Below: anxiety dimension breakdown with bar charts and processing pipeline configuration.

### Raw Entries

Filterable table of all raw entries with:

- **Status indicator** — green dot (processed) or yellow circle (unprocessed)
- **Blob preview** — first 120 characters of the raw content
- **Source** — where the entry came from (cli, mcp, sdk, import)
- **Processed into** — what memories were created from this entry
- **Strength bar** — visual indicator of memory strength

Click any row to expand full details including the complete blob text and provenance chain (what memories were derived from this raw entry).

**Filters:** All / Unprocessed / Processed. Adjustable limit (50-500).

### Memories

Sub-tabs for each memory type: Episodes, Beliefs, Values, Goals, Notes, Relationships, Drives. Each shows a table with type-specific fields:

| Memory Type | Key Fields |
|-------------|-----------|
| Episodes | Objective, outcome, confidence, emotional valence/arousal |
| Beliefs | Statement, type, confidence, scope |
| Values | Name, statement, priority |
| Goals | Title, type, priority, status |
| Notes | Content, type, processed status |
| Relationships | Entity name/type, relationship type, sentiment |
| Drives | Type, intensity, focus areas |

Click any row to see full detail including all fields and the provenance chain — both what this memory was derived from and what memories were derived from it.

### Suggestions

Pending memory suggestions with status (pending/promoted/rejected), type, confidence score, content preview, source raw IDs, and promotion target.

### Audit Log

Chronological list of all memory operations with timestamp, operation type, memory type, memory ID, and actor. Adjustable limit.

### Settings

Stack settings (enforce_provenance, stack_state, etc.) and processing pipeline configuration showing each transition layer with its enabled status, model, batch size, and thresholds.

## Header Bar

The sticky header shows:

- **Stack ID** — which stack you're inspecting
- **Memory counts** — quick summary of counts per type
- **Anxiety badge** — colored badge showing overall anxiety score and level (Calm/Aware/Elevated/High/Critical)
- **Auto-refresh toggle** — when enabled, refreshes data every 5 seconds

## Typical Workflow

After seeding a corpus and processing it:

```bash
# 1. Seed
kernle -s my-agent seed repo ./my-project
kernle -s my-agent seed docs ./my-project/docs

# 2. Process
kernle -s my-agent process exhaust

# 3. Inspect
python dev/dashboard.py --stack my-agent
```

In the dashboard:

1. **Overview** — verify memory counts match expectations, check anxiety score
2. **Raw Entries** — filter to "Unprocessed" to see if anything was missed
3. **Memories → Beliefs** — check that promoted beliefs are sensible
4. **Memories → Episodes** — verify episode objective/outcome quality
5. **Audit Log** — trace the processing pipeline's decisions

## API Endpoints

The dashboard exposes a read-only JSON API that can also be used programmatically:

| Endpoint | Description |
|----------|-------------|
| `GET /api/stats` | Memory counts by type |
| `GET /api/anxiety` | Anxiety score and dimensions |
| `GET /api/raw?limit=200&processed=true` | Raw entries (filterable) |
| `GET /api/raw/{id}` | Single raw entry detail |
| `GET /api/episodes?limit=100` | Episodes |
| `GET /api/beliefs?limit=100` | Beliefs |
| `GET /api/values` | Values |
| `GET /api/goals` | Goals |
| `GET /api/notes?limit=100` | Notes |
| `GET /api/relationships` | Relationships |
| `GET /api/drives` | Drives |
| `GET /api/suggestions?limit=100` | Suggestions |
| `GET /api/processing` | Processing pipeline config |
| `GET /api/provenance/{type}/{id}` | Provenance tree (derived memories) |
| `GET /api/audit?limit=100` | Audit trail |
| `GET /api/settings` | Stack settings |

All memory endpoints include forgotten and weak memories (`include_forgotten=True, include_weak=True`) to give a complete view of the stack.

## Security

The dashboard is designed for local development use:

- Binds to `127.0.0.1` only (not accessible from the network)
- Read-only — no mutation endpoints (GET only)
- No CORS headers (same-origin only)
- `X-Content-Type-Options: nosniff` on all responses
- Generic error messages (no internal detail leakage)
